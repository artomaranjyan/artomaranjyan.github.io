---
layout: talks
permalink: /talks/
title: Talks
description: 
nav: true
nav_order: 5
---


### Future Talks

<ol start="15" reversed>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://opt-ml.org/index.html">Workshop on Optimization for Machine Learning (NeurIPS 2024)</a> </strong></div> 
        <div style="text-align: right;">Vancouver, Canada</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Vancouver Convention Center</div> 
        <div style="text-align: right;">December 15, 2024</div> 
   </div>
   Presenting
   <ul>
       <li><strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong></li>
       <li><strong>Differentially Private Random Block Coordinate Descent</strong></li>
       <li><strong>LoCoDL: Communication-Efficient Distributed Learning with Local Training and Compression</strong></li>
   </ul>
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong>Machine Learning Research at Apple</strong></div> 
        <div style="text-align: right;">Online</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Seminar</div> 
        <div style="text-align: right;">November 21, 2024</div> 
   </div>
   Invited by <span style="color: red;">Samy Bengio</span> to give a talk on <strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong>
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://deepmath-conference.com/">Conference on the Mathematical Theory of Deep Neural Networks</a> </strong></div> 
        <div style="text-align: right;">Philadelphia, USA</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>TBA</div> 
        <div style="text-align: right;">November 15 - 16, 2024</div> 
   </div>
   Presenting a poster on <strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong>
  </li>
</ol>

### 2024 Talks and Poster Presentations

<ol start="12" reversed>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://cemse.kaust.edu.sa/events/event/e-poster-competition">CEMSE E-Poster Competition</a> </strong></div> 
        <div style="text-align: right;">KAUST, Saudi Arabia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>KAUST</div> 
        <div style="text-align: right;">October 10, 2024</div> 
   </div>
   Presented poster on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [3rd place]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://gmg70.com/">Analysis, PDEs and Applications</a> </strong></div> 
        <div style="text-align: right;">Yerevan, Armenia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Yerevan State University</div> 
        <div style="text-align: right;">July 6, 2024</div> 
   </div>
   Delivered a talk on <strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong> [<a href="https://gmg70.com/downloads/ConferenceAbstracts.pdf#page=19">abstract</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://cemse.kaust.edu.sa/events/event/snsl-workshop-2024">Stochastic Numerics and Statistical Learning</a> </strong></div> 
        <div style="text-align: right;">KAUST, Saudi Arabia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>KAUST</div> 
        <div style="text-align: right;">May 27, 2024</div> 
   </div>
   Presented poster on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_Rising_Stars.pdf">poster</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong>CS 331, Stochastic Gradient Descent Methods</strong></div> 
        <div style="text-align: right;">KAUST, Saudi Arabia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>KAUST</div> 
        <div style="text-align: right;">May 5, 2024</div> 
   </div>
   Delivered a guest lecture on <strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong>
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://groups.oist.jp/mlss">The Machine Learning Summer School in Okinawa 2024</a> </strong></div> 
        <div style="text-align: right;">Okinawa, Japan</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Okinawa Institute of Science and Technology (OIST) </div> 
        <div style="text-align: right;">March 13, 2024</div> 
   </div>
   Presented poster on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_MLSS_Okinawa.pdf">poster</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://cemse.kaust.edu.sa/ai/aii-symp-2024">KAUST Rising Stars in AI Symposium 2024</a> </strong></div> 
        <div style="text-align: right;">KAUST, Saudi Arabia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>KAUST</div> 
        <div style="text-align: right;">February 21, 2024</div> 
   </div>
   Presented poster on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_Rising_Stars.pdf">poster</a>]
  </li>
</ol>

### 2023 Talks and Poster Presentations

<ol start="6" reversed>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong>Group Seminar</strong></div> 
        <div style="text-align: right;">KAUST, Saudi Arabia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>KAUST</div> 
        <div style="text-align: right;">November 16, 2023</div> 
   </div>
   Delivered a talk on <strong>Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</strong>
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://warwick.ac.uk/fac/sci/statistics/news/algorithms-seminars/#:~:text=06/10-,Artavazd%20Maranjyan,-Link%20opens%20in">Algorithms & Computationally Intensive Inference seminars</a> </strong></div> 
        <div style="text-align: right;">Coventry, England</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>University of Warwick</div> 
        <div style="text-align: right;">October 6, 2023</div> 
   </div>
   Delivered a talk on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://warwick.ac.uk/fac/sci/statistics/news/algorithms-seminars/slides_2023_10_06_arto_maranjyan_gradskip.pdf">slides</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="http://mathconf.sci.am/index.html">Mathematics in Armenia: Advances and Perspectives</a> </strong></div> 
        <div style="text-align: right;">Yerevan, Armenia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Yerevan State University</div> 
        <div style="text-align: right;">July 5, 2023</div> 
   </div>
   Delivered a talk on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="http://mathconf.sci.am/MiA2023AbstractsBook.pdf#page=60">abstract</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://groups.google.com/g/ml-reading-group-yerevan/c/F_1OGqeFImY/m/BGDIqZAWBQAJ">Machine Learning Reading Group Yerevan</a> </strong></div> 
        <div style="text-align: right;">Yerevan, Armenia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Yerevan State University</div> 
        <div style="text-align: right;">March 10, 2023</div> 
   </div>
   Delivered a talk on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://www.youtube.com/watch?v=w9iHPgE82oo">video (Armenian)</a>]
  </li>
</ol>

### 2022 Talks and Poster Presentations

<ol start="2" reversed>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://sites.google.com/view/one-world-seminar-series-flow/archive/2022?authuser=0#h.99nho9x1b8ju">Federated Learning One World Seminar (FLOW)</a> </strong></div> 
        <div style="text-align: right;">Online</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Online</div> 
        <div style="text-align: right;">December 7, 2022</div> 
   </div>
   Delivered a talk on <strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong> [<a href="https://youtu.be/WWhY5tO-FiM">video</a>]
  </li>
  <li>
    <div style="display: flex; justify-content: space-between;"> 
        <div><strong> <a href="https://groups.google.com/g/ml-reading-group-yerevan/c/-TZmYEWATuI">Machine Learning Reading Group Yerevan</a> </strong></div> 
        <div style="text-align: right;">Yerevan, Armenia</div> 
   </div>
   <div style="display: flex; justify-content: space-between;"> 
        <div>Yerevan State University</div> 
        <div style="text-align: right;">April 10, 2022</div> 
   </div>
   Delivered a talk on <strong>ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication Acceleration! Finally!</strong>
  </li>
</ol>